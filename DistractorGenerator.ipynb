{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4780,
     "status": "ok",
     "timestamp": 1570962215721,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "wYBr0c5-mYMv",
    "outputId": "5dd04359-d1a0-4daf-be51-eb13a32b3dc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout, Input, Activation, Dense, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2051,
     "status": "ok",
     "timestamp": 1570962222200,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "FzagamXom6h_",
    "outputId": "a6d59b7c-0c25-4f97-c9cf-870c96dd2dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.95)\n",
    "config = tf.ConfigProto(log_device_placement=True,gpu_options=gpu_options)\n",
    "sess = tf.Session(config = config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wrf4nYcsmYNG"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = './DataSet/Train.csv'\n",
    "TEST_PATH = './DataSet/Results.csv'\n",
    "train_epochs = 100\n",
    "batch_size = 32\n",
    "lstm_units = 64\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "s9FhJKRhmYNW"
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "untv4rbqmYNj"
   },
   "outputs": [],
   "source": [
    "def cleanup(sent):\n",
    "    bad_chars = [';', ':', '!', \"*\", '\\\\','/', '~', '|', '@', '#', '%', '&', '(', ')', ',', '>', '<', '+', '=', '-', '_','.','`', '.', '[', ']','$', \"'\", '\"', '^']\n",
    "    for i in bad_chars:\n",
    "        sent = sent.replace(i, '')\n",
    "    \n",
    "    return str(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Uv8dGqwVmYNx"
   },
   "outputs": [],
   "source": [
    "def parse_stories(lines, sentences = None):\n",
    "    \n",
    "    data = []\n",
    "    for index, row in lines.iterrows():\n",
    "        ques, ans, dis = cleanup(row['question'].lower()), cleanup(row['answer_text'].lower()), row['distractor'].lower()\n",
    "        sentences.append(ques)\n",
    "        sentences.append(ans)\n",
    "        dis_list = re.findall(\"[\\\"|\\']+(.*?)\\.\\s*[\\\"|\\']+\", dis)\n",
    "        \n",
    "        if len(dis_list) == 0:\n",
    "            dis_list = re.findall(\"[\\\"|\\']+(.*?)\\.?\\s*[\\\"|\\']+\", dis)\n",
    "        \n",
    "        for dis in dis_list[:2]:\n",
    "            dis = cleanup(dis)\n",
    "            sentences.append(dis)\n",
    "            data.append([tokenize(ques), tokenize(ans), tokenize(\"START \" + dis + \" END\")])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1570962231585,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "cDrSXccBmYN8",
    "outputId": "39d99a2c-bd41-4b4e-e1e8-879f335a7e4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>The local government can deal with the problem...</td>\n",
       "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The author called Tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on Tommy</td>\n",
       "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can we deal with snake wounds according to...</td>\n",
       "      <td>Stay calm and do n't move .</td>\n",
       "      <td>'Cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was the writer 's problem when she studie...</td>\n",
       "      <td>She missed her family very much .</td>\n",
       "      <td>\"She did n't like her new school .\", \"She did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who were killed on February 5 in a small town ...</td>\n",
       "      <td>Chen Jianqing and one of her partners</td>\n",
       "      <td>'Chen Jianqing and her husband', 'Chen Jingmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>According to the writer , which of the followi...</td>\n",
       "      <td>Soccer is popular all over the world , but tru...</td>\n",
       "      <td>'Millions of people all over the world are pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>During a fire children often</td>\n",
       "      <td>panic</td>\n",
       "      <td>'know certain steps'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What 's the title of the passage ?</td>\n",
       "      <td>Five children died in a kindergarten bus accid...</td>\n",
       "      <td>'A bus accident in Deng zhou .', 'All primary ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ...                                         distractor\n",
       "0                                Meals can be served  ...  'outside the room at 3:00 p. m.', 'in the dini...\n",
       "1           It can be inferred from the passage that  ...  'If some tragedies occur again ', ' relevant d...\n",
       "2     The author called Tommy 's parents in order to  ...  'blame Tommy for his failing grades', 'blame T...\n",
       "3           It can be inferred from the passage that  ...  'idioms are the most important part in a langu...\n",
       "4  How can we deal with snake wounds according to...  ...          'Cut the wound and suck the poison out .'\n",
       "5  What was the writer 's problem when she studie...  ...  \"She did n't like her new school .\", \"She did ...\n",
       "6  Who were killed on February 5 in a small town ...  ...  'Chen Jianqing and her husband', 'Chen Jingmin...\n",
       "7  According to the writer , which of the followi...  ...  'Millions of people all over the world are pla...\n",
       "8                       During a fire children often  ...                               'know certain steps'\n",
       "9                 What 's the title of the passage ?  ...  'A bus accident in Deng zhou .', 'All primary ...\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = pd.read_csv(TRAIN_PATH)\n",
    "train_file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TBwc7TIvw1yI"
   },
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10403,
     "status": "ok",
     "timestamp": 1570962247592,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "ydZgQWBhmYOH",
    "outputId": "1056382c-c771-4f8a-8f66-26244ddd7a8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115981"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent = parse_stories(train_file, sentences)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15598,
     "status": "ok",
     "timestamp": 1570961740504,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "s6nkC9FCmYOQ",
    "outputId": "2804b5cb-e339-4a3e-b0e4-c320ebc87385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52983"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2312,
     "status": "ok",
     "timestamp": 1570962256101,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "qygaC0aLmYPA",
    "outputId": "c7e7288e-b395-4baf-a1e4-acdb0a5f4306"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "words_list = []\n",
    "for sent in sentences:\n",
    "    for word in tokenize(sent):\n",
    "        words_list.append(word)\n",
    "for i in words_list:\n",
    "    vocab.add(i)\n",
    "vocab.add('START')\n",
    "vocab.add('END')\n",
    "vocab = sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1570962257519,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "XEzgil_9mYPJ",
    "outputId": "5c3c316d-c9d9-4b92-946a-26e814760114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23535"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VZ0U0AbdmYPV"
   },
   "outputs": [],
   "source": [
    "word_idx = {vocab[i]:i for i in range(len(vocab))}\n",
    "idx_word = {i:vocab[i] for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21095,
     "status": "ok",
     "timestamp": 1570961746136,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "sRfnqh8yoCaL",
    "outputId": "1d70803a-27b3-43a9-8abe-b716d56f1cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx[\"animalsbehaviors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1570962263134,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "Q8mcVZnamYPd",
    "outputId": "7d6fdb3f-b3ba-4bfd-df9c-a30d21d01893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 105 68\n"
     ]
    }
   ],
   "source": [
    "ques_maxlen = 0\n",
    "ans_maxlen = 0\n",
    "dis_maxlen = 0\n",
    "\n",
    "for i in train_sent: #+ test_sent\n",
    "    ques_maxlen = max(ques_maxlen, len(i[0]))\n",
    "    ans_maxlen = max(ans_maxlen, len(i[1]))\n",
    "    \n",
    "    if len(i) > 2:\n",
    "        for j in i[2:]:\n",
    "            dis_maxlen = max(dis_maxlen, len(j))\n",
    "\n",
    "print(ques_maxlen, ans_maxlen, dis_maxlen)\n",
    "\n",
    "ques_maxlen = 20\n",
    "ans_maxlen = 20\n",
    "dis_maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GA4b_llumYPl"
   },
   "outputs": [],
   "source": [
    "def vectorize(data, word_idx, ques_maxlen, ans_maxlen, dis_maxlen = 0):\n",
    "    vec_ques = []\n",
    "    vec_dis = []\n",
    "    vec_ans = []\n",
    "    \n",
    "    for w in data:\n",
    "        a = []\n",
    "        q = []\n",
    "        d = []\n",
    "        \n",
    "        for i in w[0]:\n",
    "            q.append(word_idx[i])\n",
    "        \n",
    "        for i in w[1]:\n",
    "            a.append(word_idx[i])\n",
    "            \n",
    "        for i in w[2]:    \n",
    "            d.append(word_idx[i])\n",
    "            \n",
    "        vec_dis.append(d)\n",
    "        vec_ques.append(q)\n",
    "        vec_ans.append(a)\n",
    "        \n",
    "    return [pad_sequences(vec_ques, maxlen = ques_maxlen, padding='post'), pad_sequences(vec_ans, maxlen = ans_maxlen, padding='post'), pad_sequences(vec_dis, maxlen = dis_maxlen, padding='post')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OPTl8ZWUmYPs"
   },
   "outputs": [],
   "source": [
    "# idx = np.random.randint(0,len(train_sent),10000).astype(int)\n",
    "random.shuffle(train_sent)\n",
    "train_ques, train_ans, train_dis = vectorize(train_sent[:10000], word_idx, ques_maxlen, ans_maxlen, dis_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1570962853465,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "O_l1hoE-wU8l",
    "outputId": "52d649a4-de04-49e7-d5a8-9ed7a6d35f52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ques.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1570962856024,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "4OGWvzWsFUYZ",
    "outputId": "1e2d1a09-4c3f-492f-dbfb-79093fb4bf13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  783, 20995, 21669,  8912,   784, 22252, 16148, 10426, 14700,\n",
       "        8517,   782,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dis[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xRtJAqm1MtRx"
   },
   "outputs": [],
   "source": [
    "decode_output_data = np.zeros((len(train_dis), dis_maxlen, len(word_idx)), dtype='float32')\n",
    "for i, vec in enumerate(train_dis):\n",
    "    for t, word_vec in enumerate(vec):\n",
    "        if t>0:\n",
    "            decode_output_data[i, t-1, word_vec] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1570962877827,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "aGrPp46JRnr6",
    "outputId": "eabf8119-b5f3-4a3a-c848-6806eb75a551"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20, 23535)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1236,
     "status": "ok",
     "timestamp": 1570962880935,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "Sqb6RnCdONzR",
    "outputId": "932f0ad3-6b80-442e-96af-fdf1570f2ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ans = Input((ans_maxlen,))\n",
    "input_ques = Input((ques_maxlen,))\n",
    "\n",
    "encoder_ans = Embedding(input_dim = vocab_size,output_dim = 64, input_length = ans_maxlen)\n",
    "encoder_ques = Embedding(input_dim = vocab_size,output_dim = 64, input_length = ques_maxlen)\n",
    "\n",
    "encoded_ans = encoder_ans(input_ans)\n",
    "encoded_ques = encoder_ques(input_ques)\n",
    "\n",
    "dot_layer = dot([encoded_ans, encoded_ques], axes = (2,2))\n",
    "concat_layer = concatenate([encoded_ans, dot_layer])\n",
    "encoder_output,state_h,state_c = LSTM(lstm_units,return_state=True)(concat_layer)\n",
    "\n",
    "encoder_states = [state_h,state_c]\n",
    "\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_em = Embedding(len(word_idx), 64)\n",
    "decoder_embed = decoder_em(decoder_input)\n",
    "decoder = LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "decoder_output,_,_ = decoder(decoder_embed,initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(len(word_idx),activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([input_ans, input_ques ,decoder_input],decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1570962882665,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "Ndv_ckf0QfEf",
    "outputId": "950110df-fee2-4428-8b96-7a8dece1bcb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr=0.01, rho=0.9)\n",
    "model.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1570962884372,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "xIKMlMa6Pnab",
    "outputId": "31ef43e4-4213-4841-8799-82a79c17fde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 64)       1506240     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 64)       1506240     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 20, 20)       0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 84)       0           embedding_1[0][0]                \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     1506240     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  38144       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33024       embedding_3[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 23535)  1529775     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,119,663\n",
      "Trainable params: 6,119,663\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4562977,
     "status": "ok",
     "timestamp": 1570967462537,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "W2o3ZNx_QXLo",
    "outputId": "2fb68897-e779-40e3-fb74-afe492e921ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "9000/9000 [==============================] - 51s 6ms/step - loss: 2.6995 - acc: 0.6516 - val_loss: 2.4525 - val_acc: 0.6696\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 2.3016 - acc: 0.6794 - val_loss: 2.3558 - val_acc: 0.6778\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 2.1740 - acc: 0.6909 - val_loss: 2.3333 - val_acc: 0.6828\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 2.0921 - acc: 0.6998 - val_loss: 2.3492 - val_acc: 0.6843\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 2.0379 - acc: 0.7079 - val_loss: 2.3867 - val_acc: 0.6833\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.9858 - acc: 0.7157 - val_loss: 2.4139 - val_acc: 0.6845\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.9303 - acc: 0.7226 - val_loss: 2.4628 - val_acc: 0.6833\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.8928 - acc: 0.7305 - val_loss: 2.5060 - val_acc: 0.6773\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.8423 - acc: 0.7356 - val_loss: 2.5453 - val_acc: 0.6754\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.7925 - acc: 0.7415 - val_loss: 2.5720 - val_acc: 0.6739\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.7535 - acc: 0.7457 - val_loss: 2.6146 - val_acc: 0.6695\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.7244 - acc: 0.7498 - val_loss: 2.6422 - val_acc: 0.6715\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.6917 - acc: 0.7526 - val_loss: 2.6890 - val_acc: 0.6718\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.6616 - acc: 0.7561 - val_loss: 2.7081 - val_acc: 0.6697\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.6296 - acc: 0.7583 - val_loss: 2.7419 - val_acc: 0.6655\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.6071 - acc: 0.7612 - val_loss: 2.7753 - val_acc: 0.6668\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.5826 - acc: 0.7635 - val_loss: 2.7818 - val_acc: 0.6720\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.5623 - acc: 0.7660 - val_loss: 2.8317 - val_acc: 0.6646\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.5417 - acc: 0.7675 - val_loss: 2.8477 - val_acc: 0.6643\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.5192 - acc: 0.7693 - val_loss: 2.8730 - val_acc: 0.6656\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.5038 - acc: 0.7710 - val_loss: 2.8964 - val_acc: 0.6625\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.4844 - acc: 0.7722 - val_loss: 2.9189 - val_acc: 0.6627\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.4715 - acc: 0.7738 - val_loss: 2.9510 - val_acc: 0.6634\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.4555 - acc: 0.7742 - val_loss: 2.9651 - val_acc: 0.6625\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.4422 - acc: 0.7753 - val_loss: 2.9799 - val_acc: 0.6625\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.4263 - acc: 0.7766 - val_loss: 3.0192 - val_acc: 0.6607\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.4148 - acc: 0.7774 - val_loss: 3.0248 - val_acc: 0.6587\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.4009 - acc: 0.7788 - val_loss: 3.0496 - val_acc: 0.6598\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3901 - acc: 0.7791 - val_loss: 3.0714 - val_acc: 0.6579\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3781 - acc: 0.7809 - val_loss: 3.0936 - val_acc: 0.6624\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.3687 - acc: 0.7809 - val_loss: 3.1117 - val_acc: 0.6598\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3566 - acc: 0.7810 - val_loss: 3.1339 - val_acc: 0.6603\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3492 - acc: 0.7820 - val_loss: 3.1529 - val_acc: 0.6586\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.3386 - acc: 0.7831 - val_loss: 3.1544 - val_acc: 0.6586\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3287 - acc: 0.7835 - val_loss: 3.1935 - val_acc: 0.6568\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.3232 - acc: 0.7835 - val_loss: 3.1968 - val_acc: 0.6587\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.3139 - acc: 0.7850 - val_loss: 3.2154 - val_acc: 0.6558\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.3034 - acc: 0.7850 - val_loss: 3.2298 - val_acc: 0.6570\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2987 - acc: 0.7852 - val_loss: 3.2486 - val_acc: 0.6577\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2981 - acc: 0.7854 - val_loss: 3.2638 - val_acc: 0.6553\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2901 - acc: 0.7854 - val_loss: 3.2795 - val_acc: 0.6557\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2820 - acc: 0.7868 - val_loss: 3.2730 - val_acc: 0.6576\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.2750 - acc: 0.7866 - val_loss: 3.3048 - val_acc: 0.6557\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2692 - acc: 0.7877 - val_loss: 3.2878 - val_acc: 0.6548\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2631 - acc: 0.7876 - val_loss: 3.3175 - val_acc: 0.6535\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2578 - acc: 0.7875 - val_loss: 3.3380 - val_acc: 0.6543\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2532 - acc: 0.7884 - val_loss: 3.3499 - val_acc: 0.6557\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2472 - acc: 0.7888 - val_loss: 3.3564 - val_acc: 0.6539\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2454 - acc: 0.7891 - val_loss: 3.3732 - val_acc: 0.6553\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.2409 - acc: 0.7893 - val_loss: 3.3886 - val_acc: 0.6556\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.2376 - acc: 0.7895 - val_loss: 3.3866 - val_acc: 0.6557\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2335 - acc: 0.7898 - val_loss: 3.4103 - val_acc: 0.6545\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2256 - acc: 0.7912 - val_loss: 3.4020 - val_acc: 0.6563\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2252 - acc: 0.7900 - val_loss: 3.4217 - val_acc: 0.6545\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2232 - acc: 0.7905 - val_loss: 3.4218 - val_acc: 0.6530\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2149 - acc: 0.7912 - val_loss: 3.4437 - val_acc: 0.6553\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2137 - acc: 0.7908 - val_loss: 3.4398 - val_acc: 0.6562\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2132 - acc: 0.7911 - val_loss: 3.4617 - val_acc: 0.6546\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2091 - acc: 0.7908 - val_loss: 3.4678 - val_acc: 0.6549\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2062 - acc: 0.7906 - val_loss: 3.4698 - val_acc: 0.6538\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.2026 - acc: 0.7910 - val_loss: 3.4753 - val_acc: 0.6513\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1991 - acc: 0.7922 - val_loss: 3.4966 - val_acc: 0.6509\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1970 - acc: 0.7918 - val_loss: 3.5113 - val_acc: 0.6524\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1956 - acc: 0.7922 - val_loss: 3.4978 - val_acc: 0.6548\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1899 - acc: 0.7926 - val_loss: 3.5231 - val_acc: 0.6518\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1909 - acc: 0.7930 - val_loss: 3.5469 - val_acc: 0.6513\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1836 - acc: 0.7926 - val_loss: 3.4954 - val_acc: 0.6541\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1833 - acc: 0.7929 - val_loss: 3.5464 - val_acc: 0.6516\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1815 - acc: 0.7935 - val_loss: 3.5362 - val_acc: 0.6539\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1789 - acc: 0.7935 - val_loss: 3.5561 - val_acc: 0.6533\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1713 - acc: 0.7942 - val_loss: 3.5504 - val_acc: 0.6531\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1702 - acc: 0.7948 - val_loss: 3.5854 - val_acc: 0.6525\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1707 - acc: 0.7944 - val_loss: 3.5794 - val_acc: 0.6531\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1645 - acc: 0.7952 - val_loss: 3.5650 - val_acc: 0.6530\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1657 - acc: 0.7945 - val_loss: 3.5742 - val_acc: 0.6523\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1618 - acc: 0.7951 - val_loss: 3.5679 - val_acc: 0.6526\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1642 - acc: 0.7945 - val_loss: 3.5964 - val_acc: 0.6526\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1633 - acc: 0.7945 - val_loss: 3.6286 - val_acc: 0.6500\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1626 - acc: 0.7947 - val_loss: 3.6169 - val_acc: 0.6489\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1592 - acc: 0.7952 - val_loss: 3.6021 - val_acc: 0.6539\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1617 - acc: 0.7954 - val_loss: 3.6192 - val_acc: 0.6523\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1585 - acc: 0.7944 - val_loss: 3.6223 - val_acc: 0.6514\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1508 - acc: 0.7953 - val_loss: 3.6309 - val_acc: 0.6514\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1502 - acc: 0.7963 - val_loss: 3.6200 - val_acc: 0.6523\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1527 - acc: 0.7953 - val_loss: 3.6512 - val_acc: 0.6507\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1476 - acc: 0.7950 - val_loss: 3.6499 - val_acc: 0.6499\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1446 - acc: 0.7957 - val_loss: 3.6381 - val_acc: 0.6541\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1451 - acc: 0.7962 - val_loss: 3.6641 - val_acc: 0.6511\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1404 - acc: 0.7962 - val_loss: 3.6505 - val_acc: 0.6534\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1370 - acc: 0.7968 - val_loss: 3.6589 - val_acc: 0.6504\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1373 - acc: 0.7973 - val_loss: 3.6875 - val_acc: 0.6494\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1341 - acc: 0.7971 - val_loss: 3.6861 - val_acc: 0.6511\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1346 - acc: 0.7969 - val_loss: 3.6911 - val_acc: 0.6504\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1334 - acc: 0.7969 - val_loss: 3.6810 - val_acc: 0.6510\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1315 - acc: 0.7975 - val_loss: 3.6699 - val_acc: 0.6506\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 45s 5ms/step - loss: 1.1296 - acc: 0.7974 - val_loss: 3.6921 - val_acc: 0.6498\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1253 - acc: 0.7981 - val_loss: 3.7001 - val_acc: 0.6492\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1230 - acc: 0.7980 - val_loss: 3.6946 - val_acc: 0.6523\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1247 - acc: 0.7977 - val_loss: 3.6883 - val_acc: 0.6511\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 46s 5ms/step - loss: 1.1236 - acc: 0.7979 - val_loss: 3.6901 - val_acc: 0.6507\n"
     ]
    }
   ],
   "source": [
    "text_model = model.fit([train_ans, train_ques, train_dis],decode_output_data,batch_size=32,epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1570967599132,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "KwSiSUbIRKVP",
    "outputId": "7c78eb30-08ee-4c58-ec49-36ca7a94a666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 64)       1506240     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 64)       1506240     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 20, 20)       0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 84)       0           embedding_1[0][0]                \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  38144       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,050,624\n",
      "Trainable params: 3,050,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model([input_ans, input_ques], encoder_states)\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_state_input_h = Input(shape=(64,))\n",
    "decoder_state_input_c = Input(shape=(64,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embed2 = decoder_em(decoder_input)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder(decoder_embed2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model([decoder_input] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nc1j_vh20i2V"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(ques_seq, ans_seq):\n",
    "    states_value = encoder_model.predict([ans_seq, ques_seq])\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = word_idx['START']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)# Sample a token\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = idx_word[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_word# Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == 'END' or\n",
    "           len(decoded_sentence) > dis_maxlen):\n",
    "            stop_condition = True    # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index    # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1570967604063,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "DWh4RNVL2a9b",
    "outputId": "bd85fd7d-a170-42e4-a3ea-3effa1d7e542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: [['what', 'can', 'be', 'inferred', 'about', 'titanicii', 'from', 'the', 'passage', '?'], ['titanicii', 'will', 'have', 'more', 'space', 'in', 'its', 'lifeboats', 'than', 'the', 'titanic'], ['START', 'titanicii', 'will', 'allow', 'different', 'classes', 'of', 'passengers', 'to', 'mingle', 'END']]\n",
      "Decoded sentence:  the driver world in the\n",
      "-\n",
      "Input sentence: [['from', 'this', 'passage', 'we', 'can', 'know', 'that', 'a', 'good', 'guide'], ['should', 'explain', 'something', 'that', 'visitors', 'ca', 'nt', 'understand'], ['START', 'must', 'take', 'visitors', 'to', 'the', 'taj', 'mahal', 'and', 'the', 'tiger', 'reserve', 'END']]\n",
      "Decoded sentence:  can be more important\n",
      "-\n",
      "Input sentence: [['the', 'author', 'implies', 'that', 'it', 'is', 'very', 'easy', 'to', 'enter', 'a', 'bookshop', 'and', 'buy'], ['a', 'book', 'that', 'unexpectedly', 'fascinates', 'you'], ['START', 'a', 'book', 'on', 'ancient', 'coins', 'END']]\n",
      "Decoded sentence:  a book must be get into\n",
      "-\n",
      "Input sentence: [['peter', 's', 'marriage', 'surprised', 'the', 'writer', 'because'], ['peter', 'was', 'too', 'absorbed', 'in', 'mountain', 'climbing'], ['START', 'peter', 'did', 'n', 'END']]\n",
      "Decoded sentence:  peter made up the hotel\n",
      "-\n",
      "Input sentence: [['the', 'consistent', 'quality', 'of', 'the', 'prizes', 'is', 'guaranteed', 'by'], ['the', 'make', 'up', 'of', 'the', 'panel', 'of', 'judges'], ['START', 'the', 'gender', 'of', 'the', 'judges', 'END']]\n",
      "Decoded sentence:  the new man END\n",
      "-\n",
      "Input sentence: [['it', 'is', 'generally', 'thought', 'that'], ['the', 'air', 'in', 'coastal', 'cities', 'is', 'very', 'fresh', 'and', 'healthful'], ['START', 'the', 'air', 'in', 'coastal', 'cities', 'is', 'badly', 'polluted', 'END']]\n",
      "Decoded sentence:  the moon is the largest\n",
      "-\n",
      "Input sentence: [['what', 'can', 'be', 'inferred', 'from', 'the', 'fact', 'of', 'the', 'traffic', 'accidents', 'in', 'new', 'jersey', '?'], ['the', 'legal', 'drinking', 'age', 'should', 'be', 'raised'], ['START', 'most', 'drivers', 'hoped', 'to', 'raise', 'the', 'legal', 'drinking', 'age', 'END']]\n",
      "Decoded sentence:  there are no good memory\n",
      "-\n",
      "Input sentence: [['the', 'fourth', 'wave', 'of', 'change', 'in', 'america', 's', 'higher', 'education', 'refers', 'to'], ['research', 'universities'], ['START', 'land', 'grant', 'schools', 'END']]\n",
      "Decoded sentence:  summer and teachers END\n",
      "-\n",
      "Input sentence: [['the', 'poster', 'aims', 'to'], ['encourage', 'contributions', 'for', 'the', 'next', 'issue'], ['START', 'share', 'views', 'and', 'articles', 'among', 'teachers', 'END']]\n",
      "Decoded sentence:  tell the readers that\n",
      "-\n",
      "Input sentence: [['why', 'did', 'linda', 'think', 'that', 'dolls', 'were', 'the', 'best', 'birthday', 'gifts', 'for', 'rita', '?'], ['linda', 'had', 'never', 'got', 'the', 'dream', 'doll', 'form', 'her', 'parents'], ['START', 'rita', 'looked', 'liked', 'a', 'doll', 'when', 'she', 'was', 'a', 'little', 'girl', 'END']]\n",
      "Decoded sentence:  man s man s books with\n",
      "-\n",
      "Input sentence: [['researchers', 'from', 'the', 'national', 'university', 'of', 'singapore', 'believe', 'that'], ['how', 'climate', 'change', 'affects', 'animals', 'sizes', 'has', 'not', 'been', 'found', 'clearly'], ['START', 'too', 'many', 'studies', 'on', 'animals', 'END']]\n",
      "Decoded sentence:  people in blood living\n",
      "-\n",
      "Input sentence: [['the', 'study', 'on', 'bossy', 'behavior', 'implies', 'that', 'parents'], ['should', 'be', 'strict', 'with', 'their', 'children'], ['START', 'should', 'give', 'more', 'power', 'to', 'their', 'children', 'END']]\n",
      "Decoded sentence:  should give them a life\n",
      "-\n",
      "Input sentence: [['which', 'of', 'the', 'following', 'statements', 'is', 'true', '?'], ['preschool', 'diets', 'can', 'have', 'more', 'impact', 'on', 'children', 's', 'school', 'work'], ['START', 'a', 'child', 'who', 'often', 'hasjunk', 'foodat', '3', 'is', 'bound', 'to', 'fail', 'in', 'school', 'work', 'END']]\n",
      "Decoded sentence:  a child feels safer with\n",
      "-\n",
      "Input sentence: [['which', 'of', 'the', 'following', 'is', 'not', 'true', 'according', 'to', 'the', 'text', '?'], ['a', 'team', 'of', 'divers', 'from', 'norway', 'entered', 'the', 'submarine', 'kursk', 'successfully', 'on', 'oct', '25'], ['START', 'if', 'the', 'rescue', 'work', 'did', 'within', '1018', 'days', 'there', 'would', 'be', 'about', '30', 'sailors', 'to', 'be', 'recovered', 'END']]\n",
      "Decoded sentence:  if the works as possible\n",
      "-\n",
      "Input sentence: [['which', 'of', 'the', 'following', 'is', 'dr', 'david', 's', 'opinion', '?'], ['people', 's', 'metal', 'power', 'suffers', 'if', 'they', 'are', 'lacking', 'in', 'sleep'], ['START', 'some', 'people', 'can', 'remain', 'energetic', 'with', 'only', '65', 'hours', 'sleep', 'a', 'night', 'END']]\n",
      "Decoded sentence:  people go to the heart\n",
      "-\n",
      "Input sentence: [['according', 'to', 'the', 'researchers', 'what', 'is', 'probably', 'the', 'reason', 'why', 'people', 'grow', 'happier', 'when', 'they', 'get', 'older', '?'], ['when', 'people', 'get', 'older', 'they', 'learn', 'to', 'adjust', 'their', 'feelings'], ['START', 'when', 'people', 'get', 'older', 'they', 'ca', 'nt', 'remember', 'bad', 'experiences', 'END']]\n",
      "Decoded sentence:  when that itself do nt\n",
      "-\n",
      "Input sentence: [['what', 'is', 'the', 'article', 'mainly', 'about', '?'], ['the', 'life', 'of', 'dave', 'thomas'], ['START', 'the', 'dream', 'of', 'dave', 'thomas', 'END']]\n",
      "Decoded sentence:  the history of little\n",
      "-\n",
      "Input sentence: [['what', 'does', 'the', 'title', 'taxes', 'taxes', 'and', 'more', 'taxes', 'imply', '?'], ['americans', 'are', 'not', 'satisfied', 'with', 'the', 'three', 'types', 'of', 'taxes'], ['START', 'the', 'three', 'levels', 'of', 'government', 'do', 'not', 'use', 'the', 'taxes', 'in', 'a', 'right', 'way', 'END']]\n",
      "Decoded sentence:  the book is a better\n",
      "-\n",
      "Input sentence: [['the', 'writer', 's', 'first', 'job', 'was', 'to'], ['look', 'after', 'children', 'for', 'a', 'family'], ['START', 'look', 'after', 'children', 'at', 'a', 'kindergarten', 'END']]\n",
      "Decoded sentence:  may be sent harder to\n",
      "-\n",
      "Input sentence: [['what', 'is', 'the', 'best', 'title', 'of', 'the', 'passage', '?'], ['two', 'men', 'who', 'were', 'nt', 'afraid', 'to', 'dream'], ['START', 'two', 'writers', 'who', 'were', 'n', 'END']]\n",
      "Decoded sentence:  the number of people\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(120,140):\n",
    "    ques_seq = train_ques[seq_index:seq_index+1]\n",
    "    ans_seq = train_ans[seq_index:seq_index+1]\n",
    "    translated_sent = decode_sequence(ques_seq, ans_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', train_sent[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stories_test(lines, sentences = None):\n",
    "    \n",
    "    data = []\n",
    "    for index, row in lines.iterrows():\n",
    "        ques, ans = cleanup(row['question'].lower()), cleanup(row['answer_text'].lower())\n",
    "        sentences.append(ques)\n",
    "        sentences.append(ans)\n",
    "        data.append([tokenize(ques), tokenize(ans)])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4106,
     "status": "ok",
     "timestamp": 1570969598747,
     "user": {
      "displayName": "wce oss",
      "photoUrl": "",
      "userId": "05807561843826236835"
     },
     "user_tz": -330
    },
    "id": "Q6oIbD4B-q88",
    "outputId": "cd06910f-060f-439b-8b7d-bb23153ca867"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "test_file = pd.read_csv(TEST_PATH)\n",
    "test_sent = parse_stories_test(test_file, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hMhPim6oB6uI"
   },
   "outputs": [],
   "source": [
    "def vectorize_test(data, word_idx, ques_maxlen, ans_maxlen):\n",
    "    vec_ques = []\n",
    "    vec_ans = []\n",
    "    \n",
    "    for w in data:\n",
    "        a = []\n",
    "        q = []\n",
    "        \n",
    "        for i in w[0]:\n",
    "            try:\n",
    "                q.append(word_idx[i])\n",
    "            except:\n",
    "                q.append(np.random.randint(0,len(word_idx)))\n",
    "        \n",
    "        for i in w[1]:\n",
    "            try:\n",
    "                a.append(word_idx[i])\n",
    "            except:\n",
    "                a.append(np.random.randint(0,len(word_idx)))\n",
    "            \n",
    "        vec_ques.append(q)\n",
    "        vec_ans.append(a)\n",
    "        \n",
    "    return [pad_sequences(vec_ques, maxlen = ques_maxlen, padding='post'), pad_sequences(vec_ans, maxlen = ans_maxlen, padding='post')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cM487IPcCVD1"
   },
   "outputs": [],
   "source": [
    "test_ques, test_ans = vectorize_test(test_sent, word_idx, ques_maxlen, ans_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Vcy1Up0OCom0"
   },
   "outputs": [],
   "source": [
    "dis_list = []\n",
    "for seq_index in range(len(test_file)):\n",
    "    ques_seq = test_ques[seq_index:seq_index+1]\n",
    "    ans_seq = test_ans[seq_index:seq_index+1]\n",
    "    translated_sent = decode_sequence(ques_seq, ans_seq)\n",
    "    dis_list.append(\"'\" + translated_sent + \"'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gAJRxEwpDVDY"
   },
   "outputs": [],
   "source": [
    "test_file['distractor'] = dis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wNAmwlr5EXlh"
   },
   "outputs": [],
   "source": [
    "test_file.to_csv(\"subs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DY_-xuzzFuqR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DistractorGenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
